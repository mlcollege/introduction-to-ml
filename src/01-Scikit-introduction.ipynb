{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VELOouzy1-8u"
   },
   "source": [
    "# Introduction to scikit-learn\n",
    "* Simple and efficient tools for data mining and data analysis\n",
    "* Accessible to everybody, and reusable in various contexts\n",
    "* Built on NumPy, SciPy, and matplotlib\n",
    "* Open source, commercially usable - BSD license\n",
    "* Documentation: [http://scikit-learn.org/stable/documentation.html](http://scikit-learn.org/stable/documentation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3iquKCF1-8w"
   },
   "source": [
    "## installation\n",
    "`$ pip install scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XlrbXMBA1-8y"
   },
   "source": [
    "## Loading an example dataset\n",
    "\n",
    "Scikit-learn comes with a few standard datasets, for instance the [iris](https://en.wikipedia.org/wiki/Iris_flower_data_set) dataset for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6lXrzdk1-8z"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print(iris.data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eI9YdIm1-85"
   },
   "outputs": [],
   "source": [
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZZRdAei1-87"
   },
   "source": [
    "![Sepal vs. Petal](https://github.com/mlcollege/introduction-to-ml/blob/master/src/images/sepal-petal.jpg?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWObDGsu1-88"
   },
   "outputs": [],
   "source": [
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMA23SB41-8-"
   },
   "outputs": [],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEp-_rFF1-9A"
   },
   "source": [
    "## Data preparation\n",
    "In order to be able to measure the performance of an estimator, we need to split the data into train and test data sets. Shuffling is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c94jhbmk1-9A"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1)\n",
    "print('Train size: {}'.format(len(X_train)))\n",
    "print('Test size: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wc_wSWhv1-9C"
   },
   "source": [
    "## Learning and predicting\n",
    "In the case of the Iris dataset, the task is to predict, given a feature vector, which species the flower belong to. We are given samples of each of the 3 possible classes on which we fit an estimator to be able to predict the species to which unseen samples belong.\n",
    "\n",
    "An example of an estimator is the class [sklearn.naive_bayes.GaussianNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) that implements Gaussian Naive Bayes classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FC9Zuqdd1-9E"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print (y_pred)\n",
    "print(iris.target_names[y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GCAOei_C1-9J"
   },
   "outputs": [],
   "source": [
    "print(clf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "amX8b7z61-9L"
   },
   "source": [
    "## Model persistence\n",
    "It is possible to save a model in Scikit-learn by using Pythonâ€™s built-in persistence model, namely [pickle](https://docs.python.org/2/library/pickle.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32QKWwqU1-9M"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/tmp/model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "with open('/tmp/model.pkl', 'rb') as f:\n",
    "    clf2 = pickle.load(f)\n",
    "    print(iris.target_names[clf2.predict(X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5las7u7h1-9O"
   },
   "source": [
    "## Model evaluation\n",
    "Scikit-learn provides implementation of all methods you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISq3bUSd1-9O"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print (\"Test accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print ()\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHJq_w431-9Q"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "print (\"Train accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred)))\n",
    "print ()\n",
    "print(metrics.classification_report(y_train, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stpa1ZHz1-9S"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "we3dQC6m1-9W"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "folds = 10\n",
    "acccuracies = cross_val_score(clf, iris.data, iris.target, cv=folds, scoring='accuracy')\n",
    "print('Cross-validated accuracy: {:.2f} with standard deviation {:.2f}'.format(acccuracies.mean(), acccuracies.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UgDITea1-9b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve, ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=20, test_size=0.1, random_state=0)\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    clf,\n",
    "    iris.data, iris.target,\n",
    "    train_sizes=range(5,99,5),\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "#train_scores_std = np.std(train_scores, axis=1)\n",
    "#test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "#plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "#                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "#                     color=\"r\")\n",
    "#plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "#                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Train accuracy\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test accuracy\")\n",
    "\n",
    "plt.xlabel(\"Training examples\")\n",
    "\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-Scikit-introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
