{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "11-Regression-rnn.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH5JDsNcs3uw",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Network Regression task - Bike sharing\n",
        "\n",
        "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return has become automatic. Through these systems, a user is able to easily rent a bike from a particular position and return it at another place.\n",
        "\n",
        "The dataset contains the hourly count of rental bikes between years 2011 and 2012 in the Capital Bikeshare system (Wasington DC) with the corresponding weather and seasonal information.\n",
        "\n",
        "The goal of this task is to train a regressor to predict total counts of bike rentals based on the provided features for a given hour. \n",
        "\n",
        "## Data source\n",
        "[http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\n",
        "\n",
        "## Feature description\n",
        "* **dteday** - date time stamot\n",
        "* **season** - season (1: spring, 2: summer, 3: fall, 4: winter)\n",
        "* **yr** - year (0: 2011, 1: 2012)\n",
        "* **mnth** - month (1 to 12)\n",
        "* **hr** - hour (0 to 23)\n",
        "* **holiday** - 1 if the day is a holiday, else 0 (extracted from [holiday schedules](https://dchr.dc.gov/page/holiday-schedules))\n",
        "* **weekday** - day of the week (0 to 6)\n",
        "* **workingday** - is 1 if day is neither weekend nor holiday, else 0.\n",
        "* **weathersit** \n",
        "    * 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "    * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "    * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "    * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "* **temp** - Normalized temperature in degrees of Celsius.\n",
        "* **atemp** - Normalized feeling temperature in degrees Celsius.\n",
        "* **hum** - Normalized relative humidity.\n",
        "* **windspeed** - Normalized wind speed.\n",
        "* **casual** - Count of casual users.\n",
        "* **registered** - Count of registered users.\n",
        "* **cnt** -  Count of total rental bikes including both casual and registered. This is the target value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5b-BORis3ux",
        "colab_type": "code",
        "outputId": "8ce7e05b-da6e-4ad4-a1f9-9d08eccb5353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mlcollege/introduction-to-ml/master/data/bikes.csv', sep=',')\n",
        "data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dteday  season  yr  mnth  hr  ...   hum  windspeed  casual  registered  cnt\n",
              "0  2011-01-01       1   0     1   0  ...  0.81        0.0       3          13   16\n",
              "1  2011-01-01       1   0     1   1  ...  0.80        0.0       8          32   40\n",
              "2  2011-01-01       1   0     1   2  ...  0.80        0.0       5          27   32\n",
              "3  2011-01-01       1   0     1   3  ...  0.75        0.0       3          10   13\n",
              "4  2011-01-01       1   0     1   4  ...  0.75        0.0       0           1    1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R01iWUxvs3uz",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent Neural Network Regressor\n",
        "\n",
        "Implement a recurrent neural network regressor. Sort the data by time stamp and deal with it as it was a time series. Be aware of using data from the past as test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0SaB0-3s3u0",
        "colab_type": "code",
        "outputId": "16b88602-1b18-43cc-9f12-553fa7189ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.sort_values(['dteday', 'hr'])\n",
        "data.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dteday  season  yr  mnth  hr  ...   hum  windspeed  casual  registered  cnt\n",
              "0  2011-01-01       1   0     1   0  ...  0.81        0.0       3          13   16\n",
              "1  2011-01-01       1   0     1   1  ...  0.80        0.0       8          32   40\n",
              "2  2011-01-01       1   0     1   2  ...  0.80        0.0       5          27   32\n",
              "3  2011-01-01       1   0     1   3  ...  0.75        0.0       3          10   13\n",
              "4  2011-01-01       1   0     1   4  ...  0.75        0.0       0           1    1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEzrjVms3u4",
        "colab_type": "text"
      },
      "source": [
        "### Add some features from the past\n",
        "\n",
        "Add the target feature from the previous hour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91h74jVps3u4",
        "colab_type": "code",
        "outputId": "b06f796b-c71e-4e7b-f13a-d565800cdcc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "cnt = data['cnt']\n",
        "data['hist'] = cnt.shift(1)\n",
        "data = data[1:]\n",
        "\n",
        "X_all = data[['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit','temp', 'atemp', 'hum', 'windspeed']]\n",
        "y_all = data['cnt']\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "      <th>hist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0896</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dteday  season  yr  mnth  hr  ...  windspeed  casual  registered  cnt  hist\n",
              "1  2011-01-01       1   0     1   1  ...     0.0000       8          32   40  16.0\n",
              "2  2011-01-01       1   0     1   2  ...     0.0000       5          27   32  40.0\n",
              "3  2011-01-01       1   0     1   3  ...     0.0000       3          10   13  32.0\n",
              "4  2011-01-01       1   0     1   4  ...     0.0000       0           1    1  13.0\n",
              "5  2011-01-01       1   0     1   5  ...     0.0896       0           1    1   1.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcwZxTTTs3u6",
        "colab_type": "text"
      },
      "source": [
        "### Sequences\n",
        "\n",
        "Prepare train and test data sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcFTZXPXs3u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "window = 50\n",
        "\n",
        "X_all = X_all.values\n",
        "y_all = y_all.values\n",
        "\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for i in range(window, len(X_all) + 1):\n",
        "    X_seq.append(X_all[i-window: i])\n",
        "    y_seq.append(y_all[i-1])\n",
        "\n",
        "X_seq = np.asarray(X_seq)\n",
        "y_seq = np.asarray(y_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AOSktxBs3u9",
        "colab_type": "text"
      },
      "source": [
        "### Split the data into train and test data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSd_jj7Ts3u-",
        "colab_type": "code",
        "outputId": "4eb02d6b-79da-4bad-ee9e-56d746912d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_seq, \n",
        "    y_seq,\n",
        "    random_state=1,\n",
        "    test_size=0.1)\n",
        "\n",
        "#split_index = int(X_seq.shape[0]*0.9)\n",
        "#X_train = X_seq[:split_index,:,:]\n",
        "#X_test = X_seq[split_index:,:,:]\n",
        "#y_train = y_seq[:split_index]\n",
        "#y_test = y_seq[split_index:]\n",
        "\n",
        "print('Train size: {}'.format(X_train.shape))\n",
        "print('Test size: {}'.format(X_test.shape))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: (15596, 50, 12)\n",
            "Test size: (1733, 50, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXsbzftgs3vC",
        "colab_type": "text"
      },
      "source": [
        "Standardize the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTO8cHUqs3vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_shape = X_train.shape\n",
        "test_shape = X_test.shape\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train.reshape(train_shape[0]*train_shape[1], train_shape[2]))\n",
        "X_train = scaler.transform(X_train.reshape(train_shape[0]*train_shape[1], train_shape[2])).reshape(train_shape)\n",
        "X_test = scaler.transform(X_test.reshape(test_shape[0]*test_shape[1], test_shape[2])).reshape(test_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ERl2Qfus3vE",
        "colab_type": "text"
      },
      "source": [
        "### Training a regressor\n",
        "Design and train a recurrent regression model with at least one [LSTM](https://keras.io/layers/recurrent/) layer. Use the [mean squared error](https://keras.io/losses/) loss function. Experiment with various architectures, [activation functions](https://keras.io/activations/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmcKSDRhs3vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Activation, Dropout, LSTM\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(64, input_shape=(window, 12), return_sequences=True))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(1, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAz62VJVs3vG",
        "colab_type": "text"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDDz1CZYs3vH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-G8VCXts3vK",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoHJqF-os3vL",
        "colab_type": "code",
        "outputId": "44cdf2e8-65a1-4cd3-f64a-c1f233d7c88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size = 128, epochs = 100, verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15596 samples, validate on 1733 samples\n",
            "Epoch 1/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 54326.6725 - mae: 162.6510 - val_loss: 42924.4404 - val_mae: 146.2085\n",
            "Epoch 2/100\n",
            "15596/15596 [==============================] - 26s 2ms/sample - loss: 33676.4744 - mae: 135.3574 - val_loss: 30472.4250 - val_mae: 125.0128\n",
            "Epoch 3/100\n",
            "15596/15596 [==============================] - 26s 2ms/sample - loss: 18097.0041 - mae: 85.9202 - val_loss: 14277.9186 - val_mae: 75.0910\n",
            "Epoch 4/100\n",
            "15596/15596 [==============================] - 26s 2ms/sample - loss: 11244.5203 - mae: 65.4360 - val_loss: 8596.3071 - val_mae: 56.2964\n",
            "Epoch 5/100\n",
            "15596/15596 [==============================] - 27s 2ms/sample - loss: 6363.4473 - mae: 48.6715 - val_loss: 5369.1017 - val_mae: 45.6991\n",
            "Epoch 6/100\n",
            "15596/15596 [==============================] - 28s 2ms/sample - loss: 4413.7896 - mae: 41.6950 - val_loss: 3871.0100 - val_mae: 39.0619\n",
            "Epoch 7/100\n",
            "15596/15596 [==============================] - 28s 2ms/sample - loss: 3444.5204 - mae: 37.6135 - val_loss: 2939.1064 - val_mae: 34.7340\n",
            "Epoch 8/100\n",
            "15596/15596 [==============================] - 29s 2ms/sample - loss: 2964.7303 - mae: 35.3823 - val_loss: 2280.8624 - val_mae: 30.4497\n",
            "Epoch 9/100\n",
            "15596/15596 [==============================] - 29s 2ms/sample - loss: 2617.8058 - mae: 33.5119 - val_loss: 2152.8535 - val_mae: 30.0682\n",
            "Epoch 10/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 2532.9103 - mae: 33.1599 - val_loss: 2377.5156 - val_mae: 31.6774\n",
            "Epoch 11/100\n",
            "15596/15596 [==============================] - 29s 2ms/sample - loss: 2232.8601 - mae: 31.3509 - val_loss: 1871.8644 - val_mae: 28.7973\n",
            "Epoch 12/100\n",
            "15596/15596 [==============================] - 29s 2ms/sample - loss: 2240.0806 - mae: 31.4853 - val_loss: 1866.7781 - val_mae: 28.6432\n",
            "Epoch 13/100\n",
            "15596/15596 [==============================] - 29s 2ms/sample - loss: 2124.8868 - mae: 30.8116 - val_loss: 1677.8580 - val_mae: 26.6817\n",
            "Epoch 14/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1990.4990 - mae: 29.7544 - val_loss: 1622.0245 - val_mae: 26.2096\n",
            "Epoch 15/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1870.4785 - mae: 29.0539 - val_loss: 2005.9733 - val_mae: 29.1214\n",
            "Epoch 16/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1828.5441 - mae: 28.7574 - val_loss: 1567.6161 - val_mae: 25.9692\n",
            "Epoch 17/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1827.0672 - mae: 28.5269 - val_loss: 1519.4938 - val_mae: 25.5654\n",
            "Epoch 18/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1780.1039 - mae: 28.2230 - val_loss: 1495.1401 - val_mae: 25.9665\n",
            "Epoch 19/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1659.5636 - mae: 27.3828 - val_loss: 1722.1433 - val_mae: 26.4179\n",
            "Epoch 20/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1694.7695 - mae: 27.5819 - val_loss: 1625.9270 - val_mae: 26.4879\n",
            "Epoch 21/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1640.4257 - mae: 27.2090 - val_loss: 1382.7654 - val_mae: 24.9562\n",
            "Epoch 22/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1545.0662 - mae: 26.4220 - val_loss: 1323.4907 - val_mae: 24.1496\n",
            "Epoch 23/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1507.1055 - mae: 26.1184 - val_loss: 1286.6438 - val_mae: 23.8310\n",
            "Epoch 24/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1553.6985 - mae: 26.4683 - val_loss: 1289.1869 - val_mae: 23.8335\n",
            "Epoch 25/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1487.1203 - mae: 25.9372 - val_loss: 1316.8601 - val_mae: 24.1845\n",
            "Epoch 26/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1387.7181 - mae: 25.1534 - val_loss: 1216.0040 - val_mae: 23.4306\n",
            "Epoch 27/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1434.0889 - mae: 25.5592 - val_loss: 1180.6198 - val_mae: 23.2731\n",
            "Epoch 28/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1384.9563 - mae: 25.0922 - val_loss: 1145.4936 - val_mae: 22.8165\n",
            "Epoch 29/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1392.6483 - mae: 25.2889 - val_loss: 1228.9603 - val_mae: 23.3455\n",
            "Epoch 30/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1368.6801 - mae: 25.0343 - val_loss: 1251.1561 - val_mae: 23.2015\n",
            "Epoch 31/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1335.2666 - mae: 24.8888 - val_loss: 1093.4266 - val_mae: 21.9775\n",
            "Epoch 32/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1342.0951 - mae: 24.8076 - val_loss: 1189.1801 - val_mae: 22.6050\n",
            "Epoch 33/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1274.1203 - mae: 24.1587 - val_loss: 1123.1433 - val_mae: 21.9791\n",
            "Epoch 34/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1273.7916 - mae: 24.2496 - val_loss: 1225.4771 - val_mae: 23.1987\n",
            "Epoch 35/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1304.9432 - mae: 24.2642 - val_loss: 1102.8201 - val_mae: 21.7311\n",
            "Epoch 36/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1241.3654 - mae: 23.9502 - val_loss: 1124.9465 - val_mae: 22.4744\n",
            "Epoch 37/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1243.3813 - mae: 23.9223 - val_loss: 1089.6521 - val_mae: 22.3509\n",
            "Epoch 38/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1230.0869 - mae: 23.7277 - val_loss: 1213.6000 - val_mae: 22.7961\n",
            "Epoch 39/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1176.1252 - mae: 23.2665 - val_loss: 1185.6489 - val_mae: 23.3652\n",
            "Epoch 40/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 1220.5934 - mae: 23.8226 - val_loss: 1052.4929 - val_mae: 21.5641\n",
            "Epoch 41/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1154.0194 - mae: 23.1245 - val_loss: 1141.8143 - val_mae: 21.9517\n",
            "Epoch 42/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1176.0053 - mae: 23.5042 - val_loss: 1284.2740 - val_mae: 22.7492\n",
            "Epoch 43/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1163.6004 - mae: 23.2897 - val_loss: 1086.5617 - val_mae: 21.8615\n",
            "Epoch 44/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 1137.0055 - mae: 22.9991 - val_loss: 1081.1807 - val_mae: 21.5898\n",
            "Epoch 45/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1156.6110 - mae: 23.0578 - val_loss: 1055.7933 - val_mae: 21.6138\n",
            "Epoch 46/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1092.4242 - mae: 22.6871 - val_loss: 1032.1651 - val_mae: 21.3201\n",
            "Epoch 47/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1151.2111 - mae: 23.0928 - val_loss: 1145.7595 - val_mae: 22.4494\n",
            "Epoch 48/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 1071.5310 - mae: 22.2517 - val_loss: 987.9202 - val_mae: 20.6786\n",
            "Epoch 49/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 1145.7607 - mae: 22.8413 - val_loss: 1148.5464 - val_mae: 22.3945\n",
            "Epoch 50/100\n",
            "15596/15596 [==============================] - 33s 2ms/sample - loss: 1111.9253 - mae: 22.6727 - val_loss: 1053.4312 - val_mae: 21.4137\n",
            "Epoch 51/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 1025.2643 - mae: 21.9035 - val_loss: 891.3635 - val_mae: 20.3791\n",
            "Epoch 52/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 1022.6528 - mae: 21.8503 - val_loss: 968.4429 - val_mae: 20.8606\n",
            "Epoch 53/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 1054.5905 - mae: 22.1270 - val_loss: 985.3385 - val_mae: 20.7197\n",
            "Epoch 54/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1022.9269 - mae: 21.8202 - val_loss: 1014.7230 - val_mae: 20.7940\n",
            "Epoch 55/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 1025.1030 - mae: 21.8064 - val_loss: 1034.5537 - val_mae: 21.2466\n",
            "Epoch 56/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1041.1215 - mae: 22.0247 - val_loss: 970.5783 - val_mae: 20.7453\n",
            "Epoch 57/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 1011.4700 - mae: 21.6946 - val_loss: 969.8804 - val_mae: 20.4399\n",
            "Epoch 58/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1004.9296 - mae: 21.6433 - val_loss: 867.5195 - val_mae: 19.8829\n",
            "Epoch 59/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 986.1036 - mae: 21.5970 - val_loss: 1025.9536 - val_mae: 21.7886\n",
            "Epoch 60/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 1029.0791 - mae: 21.9503 - val_loss: 928.1035 - val_mae: 20.4157\n",
            "Epoch 61/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 953.0754 - mae: 21.1554 - val_loss: 945.6529 - val_mae: 20.3050\n",
            "Epoch 62/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 984.7615 - mae: 21.4065 - val_loss: 903.5990 - val_mae: 20.3987\n",
            "Epoch 63/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 957.0240 - mae: 21.1752 - val_loss: 884.4448 - val_mae: 19.8426\n",
            "Epoch 64/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 964.5698 - mae: 21.3039 - val_loss: 879.4812 - val_mae: 20.2045\n",
            "Epoch 65/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 940.6749 - mae: 20.9912 - val_loss: 965.1345 - val_mae: 20.6608\n",
            "Epoch 66/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 929.0176 - mae: 20.8533 - val_loss: 959.0486 - val_mae: 20.2861\n",
            "Epoch 67/100\n",
            "15596/15596 [==============================] - 30s 2ms/sample - loss: 935.2141 - mae: 20.9950 - val_loss: 890.0805 - val_mae: 20.0588\n",
            "Epoch 68/100\n",
            "15596/15596 [==============================] - 33s 2ms/sample - loss: 905.2281 - mae: 20.6553 - val_loss: 861.8718 - val_mae: 19.5311\n",
            "Epoch 69/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 906.5516 - mae: 20.7146 - val_loss: 878.6359 - val_mae: 20.0657\n",
            "Epoch 70/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 906.0721 - mae: 20.7252 - val_loss: 906.8057 - val_mae: 20.4381\n",
            "Epoch 71/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 901.4565 - mae: 20.6062 - val_loss: 862.4937 - val_mae: 19.4793\n",
            "Epoch 72/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 903.8697 - mae: 20.5368 - val_loss: 872.5944 - val_mae: 19.8966\n",
            "Epoch 73/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 889.6792 - mae: 20.4838 - val_loss: 866.8057 - val_mae: 19.9627\n",
            "Epoch 74/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 890.7567 - mae: 20.4113 - val_loss: 865.4602 - val_mae: 19.8227\n",
            "Epoch 75/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 859.0990 - mae: 20.1731 - val_loss: 894.2905 - val_mae: 20.0042\n",
            "Epoch 76/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 861.3530 - mae: 20.0966 - val_loss: 865.5899 - val_mae: 19.7134\n",
            "Epoch 77/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 841.8198 - mae: 20.0914 - val_loss: 874.9801 - val_mae: 19.9046\n",
            "Epoch 78/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 860.2086 - mae: 20.1495 - val_loss: 890.9886 - val_mae: 19.8890\n",
            "Epoch 79/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 845.5046 - mae: 20.0391 - val_loss: 805.6449 - val_mae: 19.5486\n",
            "Epoch 80/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 845.6262 - mae: 19.9349 - val_loss: 812.3988 - val_mae: 19.0639\n",
            "Epoch 81/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 832.8779 - mae: 19.8435 - val_loss: 843.3618 - val_mae: 19.2804\n",
            "Epoch 82/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 839.1553 - mae: 19.8973 - val_loss: 823.8844 - val_mae: 19.3446\n",
            "Epoch 83/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 840.5800 - mae: 19.9559 - val_loss: 857.5890 - val_mae: 19.6120\n",
            "Epoch 84/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 850.2943 - mae: 20.0879 - val_loss: 941.6569 - val_mae: 20.3683\n",
            "Epoch 85/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 846.9290 - mae: 19.8620 - val_loss: 896.2891 - val_mae: 19.9335\n",
            "Epoch 86/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 853.3692 - mae: 20.0821 - val_loss: 917.0130 - val_mae: 20.3046\n",
            "Epoch 87/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 847.4793 - mae: 20.0606 - val_loss: 920.2273 - val_mae: 20.3584\n",
            "Epoch 88/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 831.6121 - mae: 19.7103 - val_loss: 913.8854 - val_mae: 19.8935\n",
            "Epoch 89/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 809.7622 - mae: 19.6789 - val_loss: 829.1682 - val_mae: 19.2925\n",
            "Epoch 90/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 772.9785 - mae: 19.2132 - val_loss: 828.2432 - val_mae: 19.5264\n",
            "Epoch 91/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 769.8127 - mae: 19.1380 - val_loss: 853.6190 - val_mae: 19.4647\n",
            "Epoch 92/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 798.1372 - mae: 19.4406 - val_loss: 826.1757 - val_mae: 19.0750\n",
            "Epoch 93/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 780.7585 - mae: 19.2852 - val_loss: 832.3893 - val_mae: 19.2106\n",
            "Epoch 94/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 804.1178 - mae: 19.4805 - val_loss: 879.9029 - val_mae: 19.9544\n",
            "Epoch 95/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 776.4765 - mae: 19.2206 - val_loss: 817.7960 - val_mae: 19.0896\n",
            "Epoch 96/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 794.8903 - mae: 19.3968 - val_loss: 878.0636 - val_mae: 19.5750\n",
            "Epoch 97/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 809.3416 - mae: 19.5360 - val_loss: 863.5201 - val_mae: 19.9051\n",
            "Epoch 98/100\n",
            "15596/15596 [==============================] - 31s 2ms/sample - loss: 731.9269 - mae: 18.7484 - val_loss: 820.7822 - val_mae: 19.4906\n",
            "Epoch 99/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 758.2892 - mae: 18.9474 - val_loss: 849.2697 - val_mae: 19.8185\n",
            "Epoch 100/100\n",
            "15596/15596 [==============================] - 32s 2ms/sample - loss: 717.9241 - mae: 18.5769 - val_loss: 808.4739 - val_mae: 18.8081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa8ca269f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MfmrFwNs3vO",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the models\n",
        "\n",
        "Measure mean squared error and mean absolute error evaluation metrics on both train and test data sets. Compute the mean and standard deviation of the target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adKNdsG7s3vO",
        "colab_type": "code",
        "outputId": "5b58eb8f-6bea-459e-a019-1b89e9d8cac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print (\"Test mean: {}, std: {}\".format(np.mean(y_test), np.std(y_test)))\n",
        "print(\"Test Root mean squared error: {:.2f}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
        "print(\"Test Mean absolute error: {:.2f}\".format(mean_absolute_error(y_test, y_pred)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test mean: 199.40911713791112, std: 185.49044320829438\n",
            "Test Root mean squared error: 28.43\n",
            "Test Mean absolute error: 18.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-nD9OYvs3vS",
        "colab_type": "code",
        "outputId": "7f69813a-7484-4ec0-d135-6604885db066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred = model.predict(X_train)\n",
        "print(\"Train Root mean squared error: %.2f\"\n",
        "      % np.sqrt(mean_squared_error(y_train, y_pred)))\n",
        "print(\"Train Mean absolute error: %.2f\"\n",
        "      % mean_absolute_error(y_train, y_pred))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Root mean squared error: 20.87\n",
            "Train Mean absolute error: 14.40\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}