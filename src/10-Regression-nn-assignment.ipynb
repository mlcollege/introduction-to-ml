{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woH8RNCRepkF"
      },
      "source": [
        "# Neural Network Regression task - Bike sharing\n",
        "\n",
        "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return has become automatic. Through these systems, a user is able to easily rent a bike from a particular position and return it at another place.\n",
        "\n",
        "The dataset contains the hourly count of rental bikes between years 2011 and 2012 in the Capital Bikeshare system (Washington DC) with the corresponding weather and seasonal information.\n",
        "\n",
        "The goal of this task is to train a regressor to predict total counts of bike rentals based on the provided features for a given hour.\n",
        "\n",
        "## Data source\n",
        "[http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\n",
        "\n",
        "## Feature description\n",
        "* **dteday** - date time stamot\n",
        "* **season** - season (1: spring, 2: summer, 3: fall, 4: winter)\n",
        "* **yr** - year (0: 2011, 1: 2012)\n",
        "* **mnth** - month (1 to 12)\n",
        "* **hr** - hour (0 to 23)\n",
        "* **holiday** - 1 if the day is a holiday, else 0 (extracted from [holiday schedules](https://dchr.dc.gov/page/holiday-schedules))\n",
        "* **weekday** - day of the week (0 to 6)\n",
        "* **workingday** - is 1 if day is neither weekend nor holiday, else 0.\n",
        "* **weathersit**\n",
        "    * 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "    * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "    * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "    * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "* **temp** - Normalized temperature in degrees of Celsius.\n",
        "* **atemp** - Normalized feeling temperature in degrees Celsius.\n",
        "* **hum** - Normalized relative humidity.\n",
        "* **windspeed** - Normalized wind speed.\n",
        "* **casual** - Count of casual users.\n",
        "* **registered** - Count of registered users.\n",
        "* **cnt** -  Count of total rental bikes including both casual and registered. This is the target value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbTyQeqJepkI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mlcollege/introduction-to-ml/master/data/bikes.csv', sep=',')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epVcezc1epkS"
      },
      "source": [
        "## Add some features from the past\n",
        "\n",
        "Since we have time stamp of every measurement, we can see the data as a time series and use data from the past. We add one feature column computed from the data of the previous hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5FzNag9epkS"
      },
      "outputs": [],
      "source": [
        "# Add features from the past: create lagged features based on previous hour\n",
        "data.sort_values(['dteday', 'hr'])\n",
        "cnt = data['cnt']\n",
        "data['hist'] = cnt.shift(1)\n",
        "data = data[1:]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVGsqSJ5epkU"
      },
      "source": [
        "## Neural Network regressor\n",
        "\n",
        "Implement a neural network regressor based on all reasonable features from the input data set. Notice that some of the features from the input data cannot be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yvWD-KaepkV"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "Prepare train and test data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D3nUXb0epkV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare the data including the new 'hist' feature\n",
        "X_all = data[['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit','temp', 'atemp', 'hum', 'windspeed', 'hist']]\n",
        "y_all = data['cnt']\n",
        "\n",
        "# Split data into training (80%) and test (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all,\n",
        "    y_all,\n",
        "    random_state=1,\n",
        "    test_size=0.2)\n",
        "\n",
        "print('Train size: {}'.format(len(X_train)))\n",
        "print('Test size: {}'.format(len(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5efFOi5epkX"
      },
      "source": [
        "Standardize the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-qxoI-_epke"
      },
      "outputs": [],
      "source": [
        "# TODO: Standardize features\n",
        "# 1. Create StandardScaler instance\n",
        "# 2. Fit scaler on training data X_train\n",
        "# 3. Transform both X_train and X_test using the fitted scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwbqJpCjepkg"
      },
      "source": [
        "### Training a regressor\n",
        "Design and train a regression model. Use the [mean squared error](https://keras.io/losses/) loss function. Experiment with various architectures, [activation functions](https://keras.io/activations/) and [optimizers](https://keras.io/optimizers/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7SVVejHepkg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "\n",
        "# TODO: Design a neural network for regression\n",
        "# 1. Create a Sequential model\n",
        "# 2. Add Dense layers with tanh or relu activations\n",
        "# 3. Final output layer should have 1 neuron with appropriate activation\n",
        "# 4. Consider regularization with Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFl3yjmbepki"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLIBzhC7epkj"
      },
      "outputs": [],
      "source": [
        "# TODO: Compile the model\n",
        "# Use mean_squared_error loss for regression\n",
        "# Try different optimizers (adam, sgd, rmsprop)\n",
        "# Use mae (mean absolute error) as a metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBD2LemLepkr"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joY4wvuKepks"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the model\n",
        "# Use model.fit() with appropriate parameters:\n",
        "# - batch_size: typically 128\n",
        "# - epochs: number of passes through training data (50-500)\n",
        "# - validation_data: use test set for validation during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnElE32Cepku"
      },
      "source": [
        "### Evaluate the models\n",
        "\n",
        "Measure mean squared error and mean absolute error evaluation metrics on both train and test data sets. Compute the mean and standard deviation of the target values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGS_R6Poepkv"
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate the model\n",
        "# 1. Make predictions on both test and training sets\n",
        "# 2. Calculate mean and std of target values\n",
        "# 3. Calculate Root Mean Squared Error (RMSE)\n",
        "# 4. Calculate Mean Absolute Error (MAE)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "10-Regression-nn-assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
