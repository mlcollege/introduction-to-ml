{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2lz6lOOS4wLz"
      },
      "source": [
        "# Classification task - Room occupancy 2\n",
        "\n",
        "Some machine learning methods, namely Support Vector Machines, require standardized features. This means that every numerical feature should have zero mean and unit standard deviation. Implement normalization using standard Scikit-learn tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "m9gGIPB64wL4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mlcollege/introduction-to-ml/master/data/occupancy.csv', sep=',')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IAWo5aer4wL9"
      },
      "source": [
        "## Standardized classifier\n",
        "Implement a classifier with standardized features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I8TQgwjo4wL-"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "EZ48vpvW4wL-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare the data by separating features and target variable\n",
        "X_all = data[['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio']]\n",
        "y_all = data['Occupancy']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all, \n",
        "    y_all,\n",
        "    random_state=1,\n",
        "    test_size=0.1)\n",
        "\n",
        "print('Train size: {}'.format(len(X_train)))\n",
        "print('Test size: {}'.format(len(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VBZ1xGlZ4wMD"
      },
      "source": [
        "### Training a standardized classifier\n",
        "\n",
        "Implement a [Support Vector Machines](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) classifier with feature standardization. You can use the standard Scikit-learn tools:\n",
        "* [sklearn.preprocessing.StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n",
        "* [sklearn.pipeline.Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
        "\n",
        "Remember that standardization has to be estimated on the train set only and applied to both the train and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7d4N97Q44wMD"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create and fit StandardScaler on the training data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "print(scaler.transform(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Zu1kdCSq4wMG"
      },
      "outputs": [],
      "source": [
        "# Verify standardization: check mean and std of first feature\n",
        "print(scaler.transform(X_train)[:,0].mean())\n",
        "print(scaler.transform(X_train)[:,0].std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BfXRiOZG4wMJ"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline that combines StandardScaler with SVM\n",
        "# This ensures standardization is applied consistently to train and test data\n",
        "clf_pipeline = Pipeline([('std', StandardScaler()),\n",
        "                         ('svm', svm.SVC(kernel='linear'))])\n",
        "\n",
        "clf_pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGIIQAKz4wMM"
      },
      "source": [
        "### Evaluate the model\n",
        "\n",
        "Implement all evaluation methods you have learned in the Scikit-learn tutorial. Analyze the effect of standardization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "uYyf4eNG4wMO"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = clf_pipeline.predict(X_test)\n",
        "\n",
        "print (\"Test accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred)))\n",
        "print ()\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Z0y1wdPv4wMQ"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the training set\n",
        "y_pred = clf_pipeline.predict(X_train)\n",
        "\n",
        "print (\"Train accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred)))\n",
        "print ()\n",
        "print(metrics.classification_report(y_train, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "03-Classification2-solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
