{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "11-Regression-rnn.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH5JDsNcs3uw",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Network Regression task - Bike sharing\n",
        "\n",
        "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return has become automatic. Through these systems, a user is able to easily rent a bike from a particular position and return it at another place.\n",
        "\n",
        "The dataset contains the hourly count of rental bikes between years 2011 and 2012 in the Capital Bikeshare system (Wasington DC) with the corresponding weather and seasonal information.\n",
        "\n",
        "The goal of this task is to train a regressor to predict total counts of bike rentals based on the provided features for a given hour. \n",
        "\n",
        "## Data source\n",
        "[http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\n",
        "\n",
        "## Feature description\n",
        "* **dteday** - date time stamot\n",
        "* **season** - season (1: spring, 2: summer, 3: fall, 4: winter)\n",
        "* **yr** - year (0: 2011, 1: 2012)\n",
        "* **mnth** - month (1 to 12)\n",
        "* **hr** - hour (0 to 23)\n",
        "* **holiday** - 1 if the day is a holiday, else 0 (extracted from [holiday schedules](https://dchr.dc.gov/page/holiday-schedules))\n",
        "* **weekday** - day of the week (0 to 6)\n",
        "* **workingday** - is 1 if day is neither weekend nor holiday, else 0.\n",
        "* **weathersit** \n",
        "    * 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "    * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "    * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "    * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "* **temp** - Normalized temperature in degrees of Celsius.\n",
        "* **atemp** - Normalized feeling temperature in degrees Celsius.\n",
        "* **hum** - Normalized relative humidity.\n",
        "* **windspeed** - Normalized wind speed.\n",
        "* **casual** - Count of casual users.\n",
        "* **registered** - Count of registered users.\n",
        "* **cnt** -  Count of total rental bikes including both casual and registered. This is the target value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5b-BORis3ux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f10fc695-0bd8-44e7-deef-7da53a6632b9"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mlcollege/introduction-to-ml/master/data/bikes.csv', sep=',')\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dteday  season  yr  mnth  hr  ...   hum  windspeed  casual  registered  cnt\n",
              "0  2011-01-01       1   0     1   0  ...  0.81        0.0       3          13   16\n",
              "1  2011-01-01       1   0     1   1  ...  0.80        0.0       8          32   40\n",
              "2  2011-01-01       1   0     1   2  ...  0.80        0.0       5          27   32\n",
              "3  2011-01-01       1   0     1   3  ...  0.75        0.0       3          10   13\n",
              "4  2011-01-01       1   0     1   4  ...  0.75        0.0       0           1    1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R01iWUxvs3uz",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent Neural Network Regressor\n",
        "\n",
        "Implement a recurrent neural network regressor. Sort the data by time stamp and deal with it as it was a time series. Be aware of using data from the past as test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0SaB0-3s3u0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "388d3385-25fe-4989-d263-b2d60eac7ace"
      },
      "source": [
        "data.sort_values(['dteday', 'hr'])\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dteday  season  yr  mnth  hr  ...   hum  windspeed  casual  registered  cnt\n",
              "0  2011-01-01       1   0     1   0  ...  0.81        0.0       3          13   16\n",
              "1  2011-01-01       1   0     1   1  ...  0.80        0.0       8          32   40\n",
              "2  2011-01-01       1   0     1   2  ...  0.80        0.0       5          27   32\n",
              "3  2011-01-01       1   0     1   3  ...  0.75        0.0       3          10   13\n",
              "4  2011-01-01       1   0     1   4  ...  0.75        0.0       0           1    1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVEzrjVms3u4",
        "colab_type": "text"
      },
      "source": [
        "### Add some features from the past\n",
        "\n",
        "Add the target feature from the previous hour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91h74jVps3u4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "645543b5-3e2c-4076-b208-ab1caa0d50dd"
      },
      "source": [
        "cnt = data['cnt']\n",
        "data['hist'] = cnt.shift(1)\n",
        "data = data[1:]\n",
        "\n",
        "X_all = data[['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit','temp', 'atemp', 'hum', 'windspeed']]\n",
        "y_all = data['cnt']\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "      <th>hist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0896</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dteday  season  yr  mnth  hr  ...  windspeed  casual  registered  cnt  hist\n",
              "1  2011-01-01       1   0     1   1  ...     0.0000       8          32   40  16.0\n",
              "2  2011-01-01       1   0     1   2  ...     0.0000       5          27   32  40.0\n",
              "3  2011-01-01       1   0     1   3  ...     0.0000       3          10   13  32.0\n",
              "4  2011-01-01       1   0     1   4  ...     0.0000       0           1    1  13.0\n",
              "5  2011-01-01       1   0     1   5  ...     0.0896       0           1    1   1.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcwZxTTTs3u6",
        "colab_type": "text"
      },
      "source": [
        "### Sequences\n",
        "\n",
        "Prepare train and test data sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcFTZXPXs3u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "window = 50\n",
        "\n",
        "X_all = X_all.values\n",
        "y_all = y_all.values\n",
        "\n",
        "X_seq = []\n",
        "y_seq = []\n",
        "for i in range(window, len(X_all) + 1):\n",
        "    X_seq.append(X_all[i-window: i])\n",
        "    y_seq.append(y_all[i-1])\n",
        "\n",
        "X_seq = np.asarray(X_seq)\n",
        "y_seq = np.asarray(y_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AOSktxBs3u9",
        "colab_type": "text"
      },
      "source": [
        "### Split the data into train and test data sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSd_jj7Ts3u-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c4c7fe8b-1a92-4cc1-cf5d-a4d74ed45e74"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_seq, \n",
        "    y_seq,\n",
        "    random_state=1,\n",
        "    test_size=0.1)\n",
        "\n",
        "#split_index = int(X_seq.shape[0]*0.9)\n",
        "#X_train = X_seq[:split_index,:,:]\n",
        "#X_test = X_seq[split_index:,:,:]\n",
        "#y_train = y_seq[:split_index]\n",
        "#y_test = y_seq[split_index:]\n",
        "\n",
        "print('Train size: {}'.format(X_train.shape))\n",
        "print('Test size: {}'.format(X_test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size: (15596, 50, 12)\n",
            "Test size: (1733, 50, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXsbzftgs3vC",
        "colab_type": "text"
      },
      "source": [
        "Standardize the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTO8cHUqs3vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_shape = X_train.shape\n",
        "test_shape = X_test.shape\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train.reshape(train_shape[0]*train_shape[1], train_shape[2]))\n",
        "X_train = scaler.transform(X_train.reshape(train_shape[0]*train_shape[1], train_shape[2])).reshape(train_shape)\n",
        "X_test = scaler.transform(X_test.reshape(test_shape[0]*test_shape[1], test_shape[2])).reshape(test_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ERl2Qfus3vE",
        "colab_type": "text"
      },
      "source": [
        "### Training a regressor\n",
        "Design and train a recurrent regression model with at least one [LSTM](https://keras.io/layers/recurrent/) layer. Use the [mean squared error](https://keras.io/losses/) loss function. Experiment with various architectures, [activation functions](https://keras.io/activations/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmcKSDRhs3vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(64, input_shape=(window, 12), return_sequences=True))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(1, activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAz62VJVs3vG",
        "colab_type": "text"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDDz1CZYs3vH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "399f9a28-63d2-4c61-cb7a-6b07a1c0851b"
      },
      "source": [
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mae'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-G8VCXts3vK",
        "colab_type": "text"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoHJqF-os3vL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "033b3d52-65d9-4151-b9ea-66e8e3d038c0"
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size = 128, epochs = 100, verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 15596 samples, validate on 1733 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "15596/15596 [==============================] - 33s 2ms/step - loss: 52165.8227 - mean_absolute_error: 159.7536 - val_loss: 40373.4765 - val_mean_absolute_error: 143.6417\n",
            "Epoch 2/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 32256.6659 - mean_absolute_error: 132.5243 - val_loss: 26797.4978 - val_mean_absolute_error: 112.5277\n",
            "Epoch 3/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 16638.9717 - mean_absolute_error: 82.2827 - val_loss: 13762.8930 - val_mean_absolute_error: 73.6526\n",
            "Epoch 4/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 10680.7873 - mean_absolute_error: 63.9493 - val_loss: 7645.3417 - val_mean_absolute_error: 51.4931\n",
            "Epoch 5/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 6030.8472 - mean_absolute_error: 47.7923 - val_loss: 5051.5433 - val_mean_absolute_error: 44.5856\n",
            "Epoch 6/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 4312.2906 - mean_absolute_error: 41.7819 - val_loss: 3266.2946 - val_mean_absolute_error: 36.0528\n",
            "Epoch 7/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 3495.4352 - mean_absolute_error: 37.9645 - val_loss: 2697.8566 - val_mean_absolute_error: 32.9216\n",
            "Epoch 8/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 3074.7860 - mean_absolute_error: 36.3749 - val_loss: 2467.0673 - val_mean_absolute_error: 31.4234\n",
            "Epoch 9/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 2669.5114 - mean_absolute_error: 33.9637 - val_loss: 2005.5078 - val_mean_absolute_error: 29.0076\n",
            "Epoch 10/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 2484.8960 - mean_absolute_error: 32.8583 - val_loss: 1877.0887 - val_mean_absolute_error: 28.0782\n",
            "Epoch 11/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 2334.4574 - mean_absolute_error: 31.8957 - val_loss: 1851.3884 - val_mean_absolute_error: 28.0002\n",
            "Epoch 12/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 2215.0820 - mean_absolute_error: 31.3849 - val_loss: 1934.4770 - val_mean_absolute_error: 28.9297\n",
            "Epoch 13/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 2145.9130 - mean_absolute_error: 30.5906 - val_loss: 2049.4615 - val_mean_absolute_error: 29.2209\n",
            "Epoch 14/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 2056.4729 - mean_absolute_error: 30.1813 - val_loss: 1743.9629 - val_mean_absolute_error: 27.4137\n",
            "Epoch 15/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1974.8095 - mean_absolute_error: 29.4590 - val_loss: 1800.2301 - val_mean_absolute_error: 27.8618\n",
            "Epoch 16/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1888.5028 - mean_absolute_error: 28.9617 - val_loss: 1513.3913 - val_mean_absolute_error: 25.2511\n",
            "Epoch 17/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1803.1004 - mean_absolute_error: 28.1011 - val_loss: 1556.4584 - val_mean_absolute_error: 25.7340\n",
            "Epoch 18/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1821.4425 - mean_absolute_error: 28.3229 - val_loss: 1455.9916 - val_mean_absolute_error: 24.8711\n",
            "Epoch 19/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1753.7915 - mean_absolute_error: 28.0741 - val_loss: 1408.9566 - val_mean_absolute_error: 24.4336\n",
            "Epoch 20/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1732.4415 - mean_absolute_error: 27.6063 - val_loss: 1670.8056 - val_mean_absolute_error: 26.5823\n",
            "Epoch 21/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1655.0360 - mean_absolute_error: 27.1687 - val_loss: 1374.0382 - val_mean_absolute_error: 24.1289\n",
            "Epoch 22/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1667.6960 - mean_absolute_error: 27.1792 - val_loss: 1609.9686 - val_mean_absolute_error: 26.1289\n",
            "Epoch 23/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1652.1466 - mean_absolute_error: 26.9262 - val_loss: 1381.2590 - val_mean_absolute_error: 23.9385\n",
            "Epoch 24/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1642.6130 - mean_absolute_error: 26.8677 - val_loss: 1350.4161 - val_mean_absolute_error: 23.9198\n",
            "Epoch 25/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1538.8283 - mean_absolute_error: 26.2216 - val_loss: 1367.4531 - val_mean_absolute_error: 24.1175\n",
            "Epoch 26/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1536.4506 - mean_absolute_error: 26.0591 - val_loss: 1301.2567 - val_mean_absolute_error: 23.5604\n",
            "Epoch 27/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1475.5310 - mean_absolute_error: 25.6024 - val_loss: 1291.0317 - val_mean_absolute_error: 23.8057\n",
            "Epoch 28/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1437.4967 - mean_absolute_error: 25.4154 - val_loss: 1224.7426 - val_mean_absolute_error: 22.6087\n",
            "Epoch 29/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1414.4661 - mean_absolute_error: 24.9791 - val_loss: 1251.7644 - val_mean_absolute_error: 23.5884\n",
            "Epoch 30/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1447.4047 - mean_absolute_error: 25.3995 - val_loss: 1338.6158 - val_mean_absolute_error: 24.2339\n",
            "Epoch 31/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1404.5875 - mean_absolute_error: 25.1178 - val_loss: 1359.7953 - val_mean_absolute_error: 24.7338\n",
            "Epoch 32/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1359.6273 - mean_absolute_error: 24.7759 - val_loss: 1161.8680 - val_mean_absolute_error: 22.9053\n",
            "Epoch 33/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1330.1050 - mean_absolute_error: 24.4579 - val_loss: 1177.3157 - val_mean_absolute_error: 22.6177\n",
            "Epoch 34/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1340.0025 - mean_absolute_error: 24.6106 - val_loss: 1229.5353 - val_mean_absolute_error: 23.0277\n",
            "Epoch 35/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1307.1416 - mean_absolute_error: 24.3411 - val_loss: 1224.3335 - val_mean_absolute_error: 22.9702\n",
            "Epoch 36/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1281.6621 - mean_absolute_error: 24.0581 - val_loss: 1226.6014 - val_mean_absolute_error: 23.0847\n",
            "Epoch 37/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1299.0193 - mean_absolute_error: 24.2132 - val_loss: 1149.7864 - val_mean_absolute_error: 22.5744\n",
            "Epoch 38/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1214.8023 - mean_absolute_error: 23.4054 - val_loss: 1097.8498 - val_mean_absolute_error: 22.3087\n",
            "Epoch 39/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1231.1405 - mean_absolute_error: 23.6556 - val_loss: 1103.8589 - val_mean_absolute_error: 22.2858\n",
            "Epoch 40/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1269.8410 - mean_absolute_error: 23.8380 - val_loss: 1142.9230 - val_mean_absolute_error: 22.7760\n",
            "Epoch 41/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1231.1620 - mean_absolute_error: 23.6038 - val_loss: 1113.8762 - val_mean_absolute_error: 21.8612\n",
            "Epoch 42/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1201.7656 - mean_absolute_error: 23.4272 - val_loss: 1089.6007 - val_mean_absolute_error: 22.1341\n",
            "Epoch 43/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1172.5012 - mean_absolute_error: 23.1632 - val_loss: 1088.9101 - val_mean_absolute_error: 22.4064\n",
            "Epoch 44/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1181.7613 - mean_absolute_error: 23.2676 - val_loss: 1022.4209 - val_mean_absolute_error: 21.1169\n",
            "Epoch 45/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1148.5883 - mean_absolute_error: 22.7997 - val_loss: 1051.8568 - val_mean_absolute_error: 21.6466\n",
            "Epoch 46/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1104.9503 - mean_absolute_error: 22.5291 - val_loss: 1124.5765 - val_mean_absolute_error: 21.9966\n",
            "Epoch 47/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1117.1505 - mean_absolute_error: 22.6198 - val_loss: 1400.4426 - val_mean_absolute_error: 24.8559\n",
            "Epoch 48/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1114.7905 - mean_absolute_error: 22.5969 - val_loss: 958.4751 - val_mean_absolute_error: 20.9708\n",
            "Epoch 49/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1098.7905 - mean_absolute_error: 22.5796 - val_loss: 1175.3326 - val_mean_absolute_error: 23.2212\n",
            "Epoch 50/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1083.6277 - mean_absolute_error: 22.3421 - val_loss: 968.2059 - val_mean_absolute_error: 21.0313\n",
            "Epoch 51/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1037.2321 - mean_absolute_error: 21.8453 - val_loss: 994.3065 - val_mean_absolute_error: 21.2399\n",
            "Epoch 52/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1030.3596 - mean_absolute_error: 21.7696 - val_loss: 985.1119 - val_mean_absolute_error: 21.1436\n",
            "Epoch 53/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1064.6607 - mean_absolute_error: 22.1167 - val_loss: 1070.8625 - val_mean_absolute_error: 21.9694\n",
            "Epoch 54/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1052.0810 - mean_absolute_error: 21.8887 - val_loss: 1049.2679 - val_mean_absolute_error: 21.7537\n",
            "Epoch 55/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1048.5860 - mean_absolute_error: 21.8902 - val_loss: 1000.5711 - val_mean_absolute_error: 20.9372\n",
            "Epoch 56/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1016.2686 - mean_absolute_error: 21.5316 - val_loss: 1048.3720 - val_mean_absolute_error: 22.0842\n",
            "Epoch 57/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1014.0578 - mean_absolute_error: 21.6555 - val_loss: 924.8348 - val_mean_absolute_error: 20.4595\n",
            "Epoch 58/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1008.7061 - mean_absolute_error: 21.6224 - val_loss: 1021.6890 - val_mean_absolute_error: 21.3880\n",
            "Epoch 59/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1021.2247 - mean_absolute_error: 21.5987 - val_loss: 978.6402 - val_mean_absolute_error: 20.6454\n",
            "Epoch 60/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 1000.7757 - mean_absolute_error: 21.5534 - val_loss: 900.8207 - val_mean_absolute_error: 20.3087\n",
            "Epoch 61/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 981.1791 - mean_absolute_error: 21.1858 - val_loss: 978.2059 - val_mean_absolute_error: 20.8949\n",
            "Epoch 62/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 985.9377 - mean_absolute_error: 21.4381 - val_loss: 919.5256 - val_mean_absolute_error: 20.5013\n",
            "Epoch 63/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 954.4605 - mean_absolute_error: 21.0388 - val_loss: 952.7040 - val_mean_absolute_error: 20.6857\n",
            "Epoch 64/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 1039.5594 - mean_absolute_error: 21.6735 - val_loss: 1003.3678 - val_mean_absolute_error: 21.4194\n",
            "Epoch 65/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 962.0503 - mean_absolute_error: 21.0220 - val_loss: 885.0897 - val_mean_absolute_error: 20.2065\n",
            "Epoch 66/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 943.2955 - mean_absolute_error: 20.8521 - val_loss: 925.6209 - val_mean_absolute_error: 20.2004\n",
            "Epoch 67/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 934.0004 - mean_absolute_error: 20.7827 - val_loss: 976.9538 - val_mean_absolute_error: 21.0494\n",
            "Epoch 68/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 958.0202 - mean_absolute_error: 21.0164 - val_loss: 948.8958 - val_mean_absolute_error: 21.1716\n",
            "Epoch 69/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 919.6977 - mean_absolute_error: 20.6146 - val_loss: 889.6690 - val_mean_absolute_error: 19.9093\n",
            "Epoch 70/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 906.7863 - mean_absolute_error: 20.5630 - val_loss: 865.7816 - val_mean_absolute_error: 19.8604\n",
            "Epoch 71/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 911.9331 - mean_absolute_error: 20.5610 - val_loss: 896.4789 - val_mean_absolute_error: 20.1198\n",
            "Epoch 72/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 881.7544 - mean_absolute_error: 20.2957 - val_loss: 909.8471 - val_mean_absolute_error: 20.1601\n",
            "Epoch 73/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 885.9800 - mean_absolute_error: 20.2540 - val_loss: 971.0269 - val_mean_absolute_error: 20.3791\n",
            "Epoch 74/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 883.1247 - mean_absolute_error: 20.3417 - val_loss: 911.5651 - val_mean_absolute_error: 20.1541\n",
            "Epoch 75/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 893.2168 - mean_absolute_error: 20.4228 - val_loss: 990.0925 - val_mean_absolute_error: 20.7971\n",
            "Epoch 76/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 831.3949 - mean_absolute_error: 19.7393 - val_loss: 858.5380 - val_mean_absolute_error: 19.6866\n",
            "Epoch 77/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 872.3725 - mean_absolute_error: 20.0771 - val_loss: 882.8778 - val_mean_absolute_error: 19.7269\n",
            "Epoch 78/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 851.4965 - mean_absolute_error: 19.8148 - val_loss: 1066.7539 - val_mean_absolute_error: 21.1613\n",
            "Epoch 79/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 886.6319 - mean_absolute_error: 20.3372 - val_loss: 1021.4196 - val_mean_absolute_error: 20.8759\n",
            "Epoch 80/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 859.9225 - mean_absolute_error: 19.9822 - val_loss: 876.9703 - val_mean_absolute_error: 19.8099\n",
            "Epoch 81/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 795.9940 - mean_absolute_error: 19.4378 - val_loss: 840.8843 - val_mean_absolute_error: 19.3085\n",
            "Epoch 82/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 819.5444 - mean_absolute_error: 19.6942 - val_loss: 860.3903 - val_mean_absolute_error: 19.7460\n",
            "Epoch 83/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 886.5783 - mean_absolute_error: 20.1960 - val_loss: 899.8892 - val_mean_absolute_error: 19.7791\n",
            "Epoch 84/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 843.5947 - mean_absolute_error: 19.7700 - val_loss: 851.1462 - val_mean_absolute_error: 19.4113\n",
            "Epoch 85/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 812.1538 - mean_absolute_error: 19.5521 - val_loss: 832.6711 - val_mean_absolute_error: 19.2451\n",
            "Epoch 86/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 808.8599 - mean_absolute_error: 19.4864 - val_loss: 901.8396 - val_mean_absolute_error: 20.4072\n",
            "Epoch 87/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 854.4693 - mean_absolute_error: 19.8113 - val_loss: 1297.1450 - val_mean_absolute_error: 24.1651\n",
            "Epoch 88/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 822.8179 - mean_absolute_error: 19.6862 - val_loss: 893.7912 - val_mean_absolute_error: 19.7818\n",
            "Epoch 89/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 787.6406 - mean_absolute_error: 19.1427 - val_loss: 834.6770 - val_mean_absolute_error: 18.8648\n",
            "Epoch 90/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 805.5660 - mean_absolute_error: 19.4309 - val_loss: 825.5930 - val_mean_absolute_error: 18.8634\n",
            "Epoch 91/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 781.1028 - mean_absolute_error: 19.1833 - val_loss: 834.0934 - val_mean_absolute_error: 19.5534\n",
            "Epoch 92/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 783.9041 - mean_absolute_error: 19.1733 - val_loss: 841.3066 - val_mean_absolute_error: 19.3932\n",
            "Epoch 93/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 762.3890 - mean_absolute_error: 18.8625 - val_loss: 808.5438 - val_mean_absolute_error: 19.0681\n",
            "Epoch 94/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 816.8862 - mean_absolute_error: 19.4354 - val_loss: 843.6679 - val_mean_absolute_error: 19.1728\n",
            "Epoch 95/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 774.8923 - mean_absolute_error: 19.0899 - val_loss: 802.7653 - val_mean_absolute_error: 18.9935\n",
            "Epoch 96/100\n",
            "15596/15596 [==============================] - 27s 2ms/step - loss: 763.6166 - mean_absolute_error: 18.9684 - val_loss: 842.3046 - val_mean_absolute_error: 19.2853\n",
            "Epoch 97/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 770.3482 - mean_absolute_error: 19.0650 - val_loss: 804.5896 - val_mean_absolute_error: 18.9765\n",
            "Epoch 98/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 765.2983 - mean_absolute_error: 18.9872 - val_loss: 907.8876 - val_mean_absolute_error: 20.1522\n",
            "Epoch 99/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 764.4179 - mean_absolute_error: 19.0409 - val_loss: 822.8235 - val_mean_absolute_error: 19.0860\n",
            "Epoch 100/100\n",
            "15596/15596 [==============================] - 26s 2ms/step - loss: 751.5456 - mean_absolute_error: 18.7928 - val_loss: 919.3653 - val_mean_absolute_error: 19.8746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6698320ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MfmrFwNs3vO",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the models\n",
        "\n",
        "Measure mean squared error and mean absolute error evaluation metrics on both train and test data sets. Compute the mean and standard deviation of the target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adKNdsG7s3vO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "581e858a-7ad6-4286-95b3-9c103cdae1bf"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print (\"Test mean: {}, std: {}\".format(np.mean(y_test), np.std(y_test)))\n",
        "print(\"Test Root mean squared error: {:.2f}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
        "print(\"Test Mean absolute error: {:.2f}\".format(mean_absolute_error(y_test, y_pred)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test mean: 199.40911713791112, std: 185.49044320829438\n",
            "Test Root mean squared error: 30.32\n",
            "Test Mean absolute error: 19.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-nD9OYvs3vS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6fa15459-51ef-4f46-a903-9e584adc21fb"
      },
      "source": [
        "y_pred = model.predict(X_train)\n",
        "print(\"Train Root mean squared error: %.2f\"\n",
        "      % np.sqrt(mean_squared_error(y_train, y_pred)))\n",
        "print(\"Train Mean absolute error: %.2f\"\n",
        "      % mean_absolute_error(y_train, y_pred))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Root mean squared error: 22.43\n",
            "Train Mean absolute error: 15.39\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}