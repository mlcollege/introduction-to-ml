{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "05-Regression2-solution.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJz7zu2wDJr7",
        "colab_type": "text"
      },
      "source": [
        "# Regression task - Bike sharing 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2RLiMCKDJsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mlcollege/introduction-to-ml/master/data/bikes.csv', sep=',')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQkEiA7YDJsQ",
        "colab_type": "text"
      },
      "source": [
        "## Add some features from the past\n",
        "\n",
        "Since we have time stamp of every measurement, we can see the data as a time series and use data from the past. Add one or more feature columns computed from the data of the previous hour.\n",
        "\n",
        "You can use the following pandas methods:\n",
        "* [df.sort_values('column_name')](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html) - sorts the rows of a data frame by the column with name 'column_name'.\n",
        "* [df.shift(periods)](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.shift.html) - Shifts index of a data frame by desired number of periods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-vJ0cugDJsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.sort_values(['dteday', 'hr'])\n",
        "cnt = data['cnt']\n",
        "data['hist'] = cnt.shift(1)\n",
        "data = data[1:]\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mn96I_EDJsS",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "Prepare train and test data sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3ikQZeqDJsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_all = data[['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit','temp', 'atemp', 'hum', 'windspeed', 'hist']]\n",
        "y_all = data['cnt']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all, \n",
        "    y_all,\n",
        "    random_state=1,\n",
        "    test_size=0.2)\n",
        "\n",
        "print('Train size: {}'.format(len(X_train)))\n",
        "print('Test size: {}'.format(len(X_test)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmcltWPNMLr3",
        "colab_type": "text"
      },
      "source": [
        "## Transform categorical attributes using one-hot encoding\n",
        "\n",
        "It doesn't make sense to treat categorical attributes (eg. week day or weathersit) as numerical values. Use [One-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBhRC4AbMTkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "column_trans = ColumnTransformer(\n",
        "    [('ohe', OneHotEncoder(categories='auto'),['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit']),\n",
        "     ('std', StandardScaler(), ['temp', 'atemp', 'hum', 'windspeed', 'hist'])\n",
        "    ], remainder='passthrough')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ0yLm2mDJsY",
        "colab_type": "text"
      },
      "source": [
        "### Training a regressor\n",
        "\n",
        "Train a regressor using the following models:\n",
        "* [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
        "* [Support Vector Machines for regression](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) (experiment with different kernels)\n",
        "* [Gradient Boosted Trees](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) (Experiment with different depths and number of trees)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gwR9WA7DJsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "regr = Pipeline([('transformer', column_trans),\n",
        "                 ('linear', LinearRegression())\n",
        "                 #('gbr', GradientBoostingRegressor(n_estimators=100, max_depth=4))\n",
        "                ])\n",
        "\n",
        "regr.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbmAu8IhDJsa",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the models\n",
        "\n",
        "Measure mean squared error and mean absolute error evaluation metrics on both train and test data sets. Compute the mean and standard deviation of the target values. Decide which model performs best on the given problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyt3ynmSDJsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "y_pred = regr.predict(X_test)\n",
        "print (\"Test mean: {}, std: {}\".format(np.mean(y_test), np.std(y_test)))\n",
        "print(\"Test Root mean squared error: {:.2f}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
        "print(\"Test Mean absolute error: {:.2f}\".format(mean_absolute_error(y_test, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bszokTgDJsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = regr.predict(X_train)\n",
        "print(\"Train Root mean squared error: %.2f\"\n",
        "      % np.sqrt(mean_squared_error(y_train, y_pred)))\n",
        "print(\"Train Mean absolute error: %.2f\"\n",
        "      % mean_absolute_error(y_train, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}