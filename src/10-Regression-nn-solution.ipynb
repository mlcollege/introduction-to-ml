{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCmoPU78ep42"
      },
      "source": [
        "# Neural Network Regression task - Bike sharing\n",
        "\n",
        "Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return has become automatic. Through these systems, a user is able to easily rent a bike from a particular position and return it at another place.\n",
        "\n",
        "The dataset contains the hourly count of rental bikes between years 2011 and 2012 in the Capital Bikeshare system (Washington DC) with the corresponding weather and seasonal information.\n",
        "\n",
        "The goal of this task is to train a regressor to predict total counts of bike rentals based on the provided features for a given hour.\n",
        "\n",
        "## Data source\n",
        "[http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)\n",
        "\n",
        "## Feature description\n",
        "* **dteday** - date time stamot\n",
        "* **season** - season (1: spring, 2: summer, 3: fall, 4: winter)\n",
        "* **yr** - year (0: 2011, 1: 2012)\n",
        "* **mnth** - month (1 to 12)\n",
        "* **hr** - hour (0 to 23)\n",
        "* **holiday** - 1 if the day is a holiday, else 0 (extracted from [holiday schedules](https://dchr.dc.gov/page/holiday-schedules))\n",
        "* **weekday** - day of the week (0 to 6)\n",
        "* **workingday** - is 1 if day is neither weekend nor holiday, else 0.\n",
        "* **weathersit**\n",
        "    * 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
        "    * 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
        "    * 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
        "    * 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
        "* **temp** - Normalized temperature in degrees of Celsius.\n",
        "* **atemp** - Normalized feeling temperature in degrees Celsius.\n",
        "* **hum** - Normalized relative humidity.\n",
        "* **windspeed** - Normalized wind speed.\n",
        "* **casual** - Count of casual users.\n",
        "* **registered** - Count of registered users.\n",
        "* **cnt** -  Count of total rental bikes including both casual and registered. This is the target value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ywJ31Avep46"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mlcollege/introduction-to-ml/master/data/bikes.csv', sep=',')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xokWamQyep5D"
      },
      "source": [
        "## Add some features from the past\n",
        "\n",
        "Since we have time stamp of every measurement, we can see the data as a time series and use data from the past. We add one feature column computed from the data of the previous hour."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyh8au_7ep5G"
      },
      "outputs": [],
      "source": [
        "# Add features from the past: create lagged features based on previous hour\n",
        "data.sort_values(['dteday', 'hr'])\n",
        "cnt = data['cnt']\n",
        "data['hist'] = cnt.shift(1)\n",
        "data = data[1:]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w0XNX95ep5J"
      },
      "source": [
        "## Neural Network regressor\n",
        "\n",
        "Implement a neural network regressor based on all reasonable features from the input data set. Notice that some of the features from the input data cannot be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uZvKUTjep5K"
      },
      "source": [
        "### Data preparation\n",
        "\n",
        "Prepare train and test data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itYtdybpep5L"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare the data including the new 'hist' feature\n",
        "X_all = data[['season', 'yr', 'mnth', 'hr', 'holiday', 'weekday', 'workingday', 'weathersit','temp', 'atemp', 'hum', 'windspeed', 'hist']]\n",
        "y_all = data['cnt']\n",
        "\n",
        "# Split data into training (80%) and test (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all,\n",
        "    y_all,\n",
        "    random_state=1,\n",
        "    test_size=0.2)\n",
        "\n",
        "print('Train size: {}'.format(len(X_train)))\n",
        "print('Test size: {}'.format(len(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhdMEq0Yep5O"
      },
      "source": [
        "Standardize the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lSgMQN6ep5O"
      },
      "outputs": [],
      "source": [
        "# Standardize features: fit scaler on training data and apply to both train and test\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llBvnJeUep5R"
      },
      "source": [
        "### Training a regressor\n",
        "Design and train a regression model. Use the [mean squared error](https://keras.io/losses/) loss function. Experiment with various architectures, [activation functions](https://keras.io/activations/) and [optimizers](https://keras.io/optimizers/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gnjl0_2Mep5T"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "\n",
        "# Design a neural network for regression\n",
        "model = Sequential()\n",
        "\n",
        "# Add first hidden layer with tanh activation\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('tanh'))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "# Add second hidden layer with tanh activation\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('tanh'))\n",
        "#model.add(Dropout(0.5))\n",
        "\n",
        "# Add output layer with relu activation (suitable for regression)\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5WwqCaTep5V"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIw7Vbapep5W"
      },
      "outputs": [],
      "source": [
        "# Compile the model with mean squared error loss and adam optimizer\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=['mae'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-JXk8UQep5Z"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apnhGmzMep5a"
      },
      "outputs": [],
      "source": [
        "# Train the model with validation on test set\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size = 128, epochs = 500, verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmCYv3B3ep5c"
      },
      "source": [
        "### Evaluate the models\n",
        "\n",
        "Measure mean squared error and mean absolute error evaluation metrics on both train and test data sets. Compute the mean and standard deviation of the target values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EuBphCRep5d"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print (\"Test mean: {}, std: {}\".format(np.mean(y_test), np.std(y_test)))\n",
        "print(\"Test Root mean squared error: {:.2f}\".format(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
        "print(\"Test Mean absolute error: {:.2f}\".format(mean_absolute_error(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYC4vyfZep5j"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the training set\n",
        "y_pred = model.predict(X_train)\n",
        "print(\"Train Root mean squared error: {:.2f}\".format(np.sqrt(mean_squared_error(y_train, y_pred))))\n",
        "print(\"Train Mean absolute error: {:.2f}\".format(mean_absolute_error(y_train, y_pred)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "10-Regression-nn-solution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
